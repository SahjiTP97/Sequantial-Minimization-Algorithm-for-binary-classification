{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92a70041-d7d7-4a8b-a209-fa88d0b9c4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the necessary libraries\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5c83ece-d1bf-4d86-8b4a-fe4128448530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspecting the data dimensions: \n",
      "\n",
      "X train dataset dimensions:  (6000, 5000)\n",
      "y train dataset dimensions:  (6000,) \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the path for the data\n",
    "data_path = 'gisette_train.data'\n",
    "labels_path = 'gisette_train.labels'\n",
    "\n",
    "# Load the data\n",
    "X_train = np.loadtxt(data_path)\n",
    "y_train = np.loadtxt(labels_path)\n",
    "\n",
    "#Inspect the data\n",
    "print('Inspecting the data dimensions: \\n')\n",
    "print('X train dataset dimensions: ', X_train.shape)\n",
    "print('y train dataset dimensions: ', y_train.shape,'\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86321197-2ccc-43f2-9426-0e03479bd5ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying results for hardwired values of hyperparameters C=1, tolerance=0.001 and max passes=5 (Linear Kernel)\n",
      "\n",
      "Estimated Weights Values Array: \n",
      " [-7.51087346e-05 -3.04385863e-05 -2.96383115e-03 ... -4.22412957e-04\n",
      " -3.59911951e-05 -3.11593633e-03] \n",
      "\n",
      "Estimated Bias Value: \n",
      " 0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize random seed to achieve reproducability\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Define the SMO class\n",
    "class SMO:\n",
    "    def __init__(self, C, tol, max_passes):\n",
    "        self.C = C\n",
    "        self.tol = tol\n",
    "        self.max_passes = max_passes\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        m, n = X.shape               # Get the number of training examples (m) and the number of features (n)\n",
    "        self.alpha = np.zeros(m)     # Initialize Lagrange multipliers (alpha) to zero\n",
    "        self.b = 0                   # Initialize the bias term (b) to zero\n",
    "        self.w = np.zeros(n)         # Initialize the weight vector (w) to zero\n",
    "        passes = 0                   # Number of passes without any alpha updates\n",
    "\n",
    "        # Main training loop\n",
    "        while passes < self.max_passes:\n",
    "            num_changed_alphas = 0          # Track the number of alpha changes in this pass\n",
    "            for i in range(m):\n",
    "                E_i = self._error(X, y, i)  # Calculate the error for the i-th training example\n",
    "                # Check if the i-th alpha violates the KKT conditions\n",
    "                if (y[i] * E_i < -self.tol and self.alpha[i] < self.C) or (y[i] * E_i > self.tol and self.alpha[i] > 0):\n",
    "                    j = self._select_j(i, m)    # Select a random j different from i\n",
    "                    E_j = self._error(X, y, j)  # Calculate the error for the j-th training example\n",
    "                    alpha_i_old, alpha_j_old = self.alpha[i], self.alpha[j] # Store the old values of alpha_i and alpha_j\n",
    "                    if y[i] != y[j]:            # Compute L and H\n",
    "                        L = max(0, self.alpha[j] - self.alpha[i])\n",
    "                        H = min(self.C, self.C + self.alpha[j] - self.alpha[i])\n",
    "                    else:\n",
    "                        L = max(0, self.alpha[i] + self.alpha[j] - self.C)\n",
    "                        H = min(self.C, self.alpha[i] + self.alpha[j])\n",
    "                    if L == H:\n",
    "                        continue\n",
    "                    eta = 2.0 * np.dot(X[i], X[j]) - np.dot(X[i], X[i]) - np.dot(X[j], X[j]) # Compute eta\n",
    "                    if eta >= 0:\n",
    "                        continue\n",
    "                    self.alpha[j] -= y[j] * (E_i - E_j) / eta      # Update alpha_j\n",
    "                    self.alpha[j] = np.clip(self.alpha[j], L, H)   # Clip alpha_j\n",
    "                    if abs(self.alpha[j] - alpha_j_old) < 1e-5:\n",
    "                        continue\n",
    "                    self.alpha[i] += y[i] * y[j] * (alpha_j_old - self.alpha[j]) # Update alpha_i\n",
    "                    # Compute b1 and b2\n",
    "                    b1 = self.b - E_i - y[i] * (self.alpha[i] - alpha_i_old) * np.dot(X[i], X[i]) - y[j] * (self.alpha[j] - alpha_j_old) * np.dot(X[i], X[j])\n",
    "                    b2 = self.b - E_j - y[i] * (self.alpha[i] - alpha_i_old) * np.dot(X[i], X[j]) - y[j] * (self.alpha[j] - alpha_j_old) * np.dot(X[j], X[j])\n",
    "                    # Update b\n",
    "                    if 0 < self.alpha[i] < self.C:\n",
    "                        self.b = b1\n",
    "                    elif 0 < self.alpha[j] < self.C:\n",
    "                        self.b = b2\n",
    "                    else:\n",
    "                        self.b = (b1 + b2) / 2\n",
    "                    num_changed_alphas += 1 # Increment the number of changed alphas\n",
    "            if num_changed_alphas == 0:     # Check if any alphas were changed\n",
    "                passes += 1\n",
    "            else:\n",
    "                passes = 0\n",
    "        self.w = self._compute_w(X, y)      # Compute the weight vector w\n",
    "\n",
    "    # Predict the labels for the input data X\n",
    "    def predict(self, X):\n",
    "        return np.sign(np.dot(X, self.w) + self.b)\n",
    "\n",
    "    # Calculate the error for the i-th training example\n",
    "    def _error(self, X, y, i):\n",
    "        return np.dot(self.w, X[i]) + self.b - y[i]\n",
    "\n",
    "    # Select a random index j different from i\n",
    "    def _select_j(self, i, m):\n",
    "        j = i\n",
    "        while j == i:\n",
    "            j = np.random.randint(0, m)\n",
    "        return j\n",
    "\n",
    "    # Compute the weight vector w\n",
    "    def _compute_w(self, X, y):\n",
    "        return np.dot(X.T, self.alpha * y)\n",
    "\n",
    "# Define hardwired parameters\n",
    "C = 1.0\n",
    "tol = 0.001\n",
    "max_passes = 5\n",
    "\n",
    "# Create an instance of the SMO class\n",
    "smo = SMO(C, tol, max_passes)\n",
    "\n",
    "# Fit the model to the training data\n",
    "smo.fit(X_train, y_train)\n",
    "\n",
    "print('Displaying results for hardwired values of hyperparameters C=1, tolerance=0.001 and max passes=5 (Linear Kernel)\\n')\n",
    "print('Estimated Weights Values Array: \\n', smo.w, '\\n')\n",
    "print('Estimated Bias Value: \\n', smo.b, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cffaed60-4805-4886-a166-dfa32b235cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Grid Search and tuning of hyperparameters C, tolerance and max passes with Linear Kernel...\n",
      "\n",
      "C: 0.1, tol: 0.001, max_passes: 5, Accuracy: 0.7580\n",
      "C: 0.1, tol: 0.001, max_passes: 10, Accuracy: 0.7733\n",
      "C: 0.1, tol: 0.01, max_passes: 5, Accuracy: 0.7607\n",
      "C: 0.1, tol: 0.01, max_passes: 10, Accuracy: 0.7587\n",
      "C: 1.0, tol: 0.001, max_passes: 5, Accuracy: 0.7758\n",
      "C: 1.0, tol: 0.001, max_passes: 10, Accuracy: 0.7557\n",
      "C: 1.0, tol: 0.01, max_passes: 5, Accuracy: 0.7510\n",
      "C: 1.0, tol: 0.01, max_passes: 10, Accuracy: 0.7667\n",
      "C: 10.0, tol: 0.001, max_passes: 5, Accuracy: 0.7890\n",
      "C: 10.0, tol: 0.001, max_passes: 10, Accuracy: 0.7782\n",
      "C: 10.0, tol: 0.01, max_passes: 5, Accuracy: 0.7763\n",
      "C: 10.0, tol: 0.01, max_passes: 10, Accuracy: 0.7663\n",
      "\n",
      "Best parameters: {'C': 10.0, 'tol': 0.001, 'max_passes': 5}, Best cross-validation accuracy: 0.7890\n",
      "\n",
      "Estimated Weights Values Array: \n",
      " [ 1.07172365e-05 -4.67327116e-05 -2.99859134e-03 ... -3.49050610e-04\n",
      " -1.14187577e-04 -2.99747771e-03] \n",
      "\n",
      "Estimated Bias Value: \n",
      " 0 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Starting Grid Search and tuning of hyperparameters C, tolerance and max passes with Linear Kernel...\\n')\n",
    "\n",
    "# Define the parameter grid\n",
    "C_values = [0.1, 1.0, 10.0]  # Different values of the regularization parameter C\n",
    "tol_values = [0.001, 0.01]   # Different values for the tolerance\n",
    "max_passes_values = [5, 10]  # Different values for the maximum number of passes\n",
    "\n",
    "kf = KFold(n_splits=5)       # Prepare cross-validation using K-Folds\n",
    "\n",
    "# Variables to store the best parameters and best score\n",
    "best_score = 0\n",
    "best_params = {'C': None, 'tol': None, 'max_passes': None}\n",
    "\n",
    "# Perform grid search\n",
    "for C in C_values:\n",
    "    for tol in tol_values:\n",
    "        for max_passes in max_passes_values:\n",
    "            accuracies = []                                                           # List to store accuracy for each fold\n",
    "            for train_index, val_index in kf.split(X_train):                          # Split the data into training and validation sets for the current fold\n",
    "                X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
    "                y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
    "\n",
    "                smo = SMO(C, tol, max_passes)                          # Create an SMO instance with the current parameters\n",
    "                smo.fit(X_train_fold, y_train_fold)                    # Train the SMO model on the training fold\n",
    "                predictions = smo.predict(X_val_fold)                  # Predict on the validation fold\n",
    "                accuracy = accuracy_score(y_val_fold, predictions)     # Calculate the accuracy on the validation fold\n",
    "                accuracies.append(accuracy)                            # Store the accuracy\n",
    "\n",
    "            avg_accuracy = np.mean(accuracies)                                                    # Calculate the average accuracy across all folds\n",
    "            print(f'C: {C}, tol: {tol}, max_passes: {max_passes}, Accuracy: {avg_accuracy:.4f}')  # Print the current parameter combination and its accuracy\n",
    "            if avg_accuracy > best_score:                                                         # Update the best parameters if the current average accuracy is better\n",
    "                best_score = avg_accuracy \n",
    "                best_params['C'] = C\n",
    "                best_params['tol'] = tol\n",
    "                best_params['max_passes'] = max_passes\n",
    "\n",
    "# Print the best parameters and the corresponding accuracy\n",
    "print(f'\\nBest parameters: {best_params}, Best cross-validation accuracy: {best_score:.4f}')\n",
    "\n",
    "# Train the final model with the best parameters\n",
    "smo_optimized = SMO(best_params['C'], best_params['tol'], best_params['max_passes'])\n",
    "smo_optimized.fit(X_train, y_train)\n",
    "\n",
    "print('\\nEstimated Weights Values Array: \\n', smo_optimized.w, '\\n')\n",
    "print('Estimated Bias Value: \\n', smo_optimized.b, '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7c53f1e-9e03-4cce-9a71-f8a6de16d24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define polynomial kernel function\n",
    "def polynomial_kernel(x1, x2, degree=3, coef0=1):\n",
    "    return (np.dot(x1, x2) + coef0) ** degree\n",
    "\n",
    "# SMO class with precomputed polynomial kernel matrix\n",
    "class SMO:\n",
    "    def __init__(self, C, tol, max_passes, kernel=polynomial_kernel, **kernel_params):\n",
    "        self.C = C\n",
    "        self.tol = tol\n",
    "        self.max_passes = max_passes\n",
    "        self.kernel = kernel\n",
    "        self.kernel_params = kernel_params\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "        self.alpha = None\n",
    "        self.b = 0\n",
    "        self.errors = None\n",
    "        self.K = None\n",
    "        self.w = None\n",
    "\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        m, n = X.shape\n",
    "        self.alpha = np.zeros(m)\n",
    "        self.errors = np.zeros(m)\n",
    "        self.b = 0\n",
    "        passes = 0\n",
    "        \n",
    "        # Precompute the kernel matrix\n",
    "        self.K = np.zeros((m, m))\n",
    "        for i in range(m):\n",
    "            for j in range(m):\n",
    "                self.K[i, j] = self.kernel(X[i], X[j], **self.kernel_params)\n",
    "\n",
    "        while passes < self.max_passes:\n",
    "            num_changed_alphas = 0\n",
    "            for i in range(m):\n",
    "                E_i = self._error(i)\n",
    "                if (y[i] * E_i < -self.tol and self.alpha[i] < self.C) or (y[i] * E_i > self.tol and self.alpha[i] > 0):\n",
    "                    j = self._select_j(i, m)\n",
    "                    E_j = self._error(j)\n",
    "                    alpha_i_old, alpha_j_old = self.alpha[i], self.alpha[j]\n",
    "                    if y[i] != y[j]:\n",
    "                        L = max(0, self.alpha[j] - self.alpha[i])\n",
    "                        H = min(self.C, self.C + self.alpha[j] - self.alpha[i])\n",
    "                    else:\n",
    "                        L = max(0, self.alpha[i] + self.alpha[j] - self.C)\n",
    "                        H = min(self.C, self.alpha[i] + self.alpha[j])\n",
    "                    if L == H:\n",
    "                        continue\n",
    "                    eta = 2.0 * self.K[i, j] - self.K[i, i] - self.K[j, j]\n",
    "                    if eta >= 0:\n",
    "                        continue\n",
    "                    self.alpha[j] -= y[j] * (E_i - E_j) / eta\n",
    "                    self.alpha[j] = np.clip(self.alpha[j], L, H)\n",
    "                    if abs(self.alpha[j] - alpha_j_old) < 1e-5:\n",
    "                        continue\n",
    "                    self.alpha[i] += y[i] * y[j] * (alpha_j_old - self.alpha[j])\n",
    "                    b1 = self.b - E_i - y[i] * (self.alpha[i] - alpha_i_old) * self.K[i, i] - y[j] * (self.alpha[j] - alpha_j_old) * self.K[i, j]\n",
    "                    b2 = self.b - E_j - y[i] * (self.alpha[i] - alpha_i_old) * self.K[i, j] - y[j] * (self.alpha[j] - alpha_j_old) * self.K[j, j]\n",
    "                    if 0 < self.alpha[i] < self.C:\n",
    "                        self.b = b1\n",
    "                    elif 0 < self.alpha[j] < self.C:\n",
    "                        self.b = b2\n",
    "                    else:\n",
    "                        self.b = (b1 + b2) / 2\n",
    "                    num_changed_alphas += 1\n",
    "            if num_changed_alphas == 0:\n",
    "                passes += 1\n",
    "            else:\n",
    "                passes = 0\n",
    "        self.w = self._compute_w(X, y)\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_predict = np.zeros(X.shape[0])\n",
    "        for i in range(X.shape[0]):\n",
    "            s = 0\n",
    "            for alpha, y, x in zip(self.alpha, self.y, self.X):\n",
    "                s += alpha * y * self.kernel(X[i], x, **self.kernel_params)\n",
    "            y_predict[i] = s\n",
    "        return np.sign(y_predict + self.b)\n",
    "\n",
    "    def _compute_w(self, X, y):\n",
    "        # Compute the weight vector\n",
    "        return np.dot((self.alpha * y), X)\n",
    "\n",
    "    def _error(self, i):\n",
    "        return np.dot((self.alpha * self.y), self.K[:, i]) + self.b - self.y[i]\n",
    "\n",
    "    def _select_j(self, i, m):\n",
    "        j = i\n",
    "        while j == i:\n",
    "            j = np.random.randint(0, m)\n",
    "        return j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53a78a5c-db05-47d7-9b25-d1eb3dcc2713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Grid Search and tuning of hyperparameters C, tolerance, max passes, degree and coef0 with Polynomial Kernel...\n",
      "\n",
      "C: 1.0, tol: 0.01, max_passes: 5, degree: 3, coef0: 0.1, Accuracy: 0.6992\n",
      "C: 1.0, tol: 0.01, max_passes: 5, degree: 4, coef0: 0.1, Accuracy: 0.9483\n",
      "C: 1.0, tol: 0.01, max_passes: 10, degree: 3, coef0: 0.1, Accuracy: 0.6398\n",
      "C: 1.0, tol: 0.01, max_passes: 10, degree: 4, coef0: 0.1, Accuracy: 0.9215\n",
      "C: 10.0, tol: 0.01, max_passes: 5, degree: 3, coef0: 0.1, Accuracy: 0.7187\n",
      "C: 10.0, tol: 0.01, max_passes: 5, degree: 4, coef0: 0.1, Accuracy: 0.9452\n",
      "C: 10.0, tol: 0.01, max_passes: 10, degree: 3, coef0: 0.1, Accuracy: 0.6995\n",
      "C: 10.0, tol: 0.01, max_passes: 10, degree: 4, coef0: 0.1, Accuracy: 0.9438\n",
      "Best parameters: {'C': 1.0, 'tol': 0.01, 'max_passes': 5, 'degree': 4, 'coef0': 0.1}, Best cross-validation accuracy: 0.9483\n",
      "\n",
      "Estimated Weights Values Array: \n",
      " [-4.39824900e-31 -1.12328153e-31 -7.88670919e-31 ... -7.09064372e-31\n",
      " -5.08980959e-31 -1.50264095e-30] \n",
      "\n",
      "Estimated Bias Value: \n",
      " 0 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize random seed to achieve reproducability\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Define the parameter grid\n",
    "C_values = [1.0, 10.0]\n",
    "tol_values = [0.01]\n",
    "max_passes_values = [5, 10]\n",
    "degree_values = [3, 4]\n",
    "coef0_values = [0.1]\n",
    "\n",
    "# Prepare cross-validation using K-Folds\n",
    "kf = KFold(n_splits=3)\n",
    "\n",
    "# Variables to store the best parameters and best score\n",
    "best_score = 0\n",
    "best_params = {'C': None, 'tol': None, 'max_passes': None, 'degree': None, 'coef0': None}\n",
    "\n",
    "print('Starting Grid Search and tuning of hyperparameters C, tolerance, max passes, degree and coef0 with Polynomial Kernel...\\n')\n",
    "\n",
    "# Perform grid search\n",
    "for C in C_values:\n",
    "    for tol in tol_values:\n",
    "        for max_passes in max_passes_values:\n",
    "            for degree in degree_values:\n",
    "                for coef0 in coef0_values:\n",
    "                    accuracies = []\n",
    "                    for train_index, val_index in kf.split(X_train):\n",
    "                        X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
    "                        y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
    "\n",
    "                        smo = SMO(C=C, tol=tol, max_passes=max_passes, kernel=polynomial_kernel, degree=degree, coef0=coef0)\n",
    "                        smo.fit(X_train_fold, y_train_fold)\n",
    "                        predictions = smo.predict(X_val_fold)\n",
    "                        accuracy = accuracy_score(y_val_fold, predictions)\n",
    "                        accuracies.append(accuracy)\n",
    "\n",
    "                    avg_accuracy = np.mean(accuracies)\n",
    "                    print(f'C: {C}, tol: {tol}, max_passes: {max_passes}, degree: {degree}, coef0: {coef0}, Accuracy: {avg_accuracy:.4f}')\n",
    "                    if avg_accuracy > best_score:\n",
    "                        best_score = avg_accuracy\n",
    "                        best_params['C'] = C\n",
    "                        best_params['tol'] = tol\n",
    "                        best_params['max_passes'] = max_passes\n",
    "                        best_params['degree'] = degree\n",
    "                        best_params['coef0'] = coef0\n",
    "\n",
    "print(f'Best parameters: {best_params}, Best cross-validation accuracy: {best_score:.4f}')\n",
    "\n",
    "# Train the final model with the best parameters\n",
    "smo_optimized = SMO(C=best_params['C'], tol=best_params['tol'], max_passes=best_params['max_passes'], \n",
    "                    kernel=polynomial_kernel, degree=best_params['degree'], coef0=best_params['coef0'])\n",
    "smo_optimized.fit(X_train, y_train)\n",
    "\n",
    "print('\\nEstimated Weights Values Array: \\n', smo_optimized.w, '\\n')\n",
    "print('Estimated Bias Value: \\n', smo_optimized.b, '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f6a433f-192f-4fb0-a40d-31a434c7deeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights and bias terms saved to smo_model_parameters.txt\n"
     ]
    }
   ],
   "source": [
    "# Define the file path to store the weights and bias term\n",
    "output_file = 'smo_model_parameters.txt'\n",
    "\n",
    "# Save the weights and bias term to the text file\n",
    "with open(output_file, 'w') as f:\n",
    "    f.write('Weights (w):\\n')\n",
    "    np.savetxt(f, smo_optimized.w, delimiter=',')\n",
    "    f.write('\\nBias term (b):\\n')\n",
    "    f.write(f'{smo_optimized.b}\\n')\n",
    "\n",
    "print(f'Weights and bias terms saved to {output_file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1ce0aa-e667-4db2-b754-a0d869a8094a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
